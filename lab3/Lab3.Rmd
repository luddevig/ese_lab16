---
title: "Lab 3 - Group 16"
author: 
- Eric BÃ¶rjesson (ericbor@student.chalmers.se)  
- Ludvig Ekman (eludvig@student.chalmers.se)  
- Wenli Zhang (wenliz@student.chalmers.se)
- Tim Grube (gusgruti@student.gu.se)
date: "`r format(Sys.time(), '%d.%m.%Y')`"
output:
  html_document:
    df_print: paged
  pdf_document:
    latex_engine: xelatex
bibliography: lab3references.bib
---

```{r setup, include=FALSE}
library(tidyverse) 
library(car) 
library(knitr)
library(psych)
library(pwr)
library(stargazer)
```

# Design an experiment

### 1. Description of context and problem

The Covid pandemic has changed the way of working for many companies and their employees. With social distancing and restrictions being implemented by governments and companies, employees are now working from home more than ever before. Even before the pandemic, experiments have been conducted in order to understand the effects of having employees working from home rather in the office. @bloom2014homework published a study where they randomly assigned employees to either work in the office or at home. The experiment indicated that working from home led to an increase in work performance, and the positive effect of working from home has also been discussed in other studies [@hill2003does]. 

The concept of technical debt within the software engineering field is recognized as something that is unavoidable and it is therefore necessary for companies to track, monitor and take action upon the technical debt [@6280547]. This experiment is intended to combine these two research topics and investigate if the work location influences the technical debt of software artifacts.

### 2. General objectives of the experiment

The objective of this experiment is to compare the quality of software artifacts produced by teams working in different locations. The aim is to investigate if the work place influences the quality of the code.  

### 3. Design of the experiment

The experiment will consist of work place being a factor and the experience of the team being a blocking variable. The factor work place will be composed of three levels: everyone working from home (Home), a mixture of the team working from home and from the office (Mix), everyone working in the office (Office). 

The experience of the team is believed to effect the outcome of the experiment, but this influence and variation is not of main interest in our study and thus as a blocking variable. The blocking variable is measured as the average time each team member has worked as a software engineer and it has two levels: less experienced (LE) and more experienced (ME). The half of the teams with lower experience are placed in the group less experienced (LE), and the half with more experience are placed in the group more experienced (ME). 

The experiment will have two controlling variables. The first is to ensure that the teams have the same workload and the second is to control the work hours and breaks, and thus ensuring consistency in work time. 

The experiment will be a block-design experiment with the following 6 experimental groups:   

- G1: Work place = Home, Experience = LE
- G2: Work place = Home, Experience = ME
- G3: Work place = Mix, Experience = LE
- G4: Work place = Mix, Experience = ME
- G5: Work place = Office, Experience = LE
- G6: Work place = Office, Experience = ME

The population consists of software engineering teams from the company ABC, where the teams are working within various business areas of the company. We aim at achieving a balanced design, so it is therefore necessary to first stratify the population based on the experience level of the team. After this, an equal amount of less and more teams can be randomly selected and the three treatments can be evenly distributed within each.

### 4. Power analysis

We have used the *pwr* package in R to conduct a power analysis. The package is based on the concepts described by Cohen [@cohen1988statistical]. According to Cohen, the five parameters power, significance criterion, degrees of freedom for numerator, degrees of freedom for denominator, and effect size, are so tightly related so that if four of them are fixed the fifth can be given. We have used the *pwr::pwr.f2.test* method to get the estimated effect size, as shown below.

Base on the experiment background we have 6 groups, so the value of u(degrees of freedom for the numerator) is 5(6-1). Compared to the control(LE, Office), we assume that the factor of work place would explain 20% influence on the outcome(Technical Debt), so effect size is 0.25(f2=0.2/1-0.2) with a confidence of 95% (sig.level=0.05) and has the power of 90% (power=0.09) to know the more efficient workplace and run experiments.

```{r power-analysis}
pwr::pwr.f2.test(u=5, f2=0.2/0.8, power=0.9)
```

From the result, we can deduce that the sample size should be at least 72 teams(66+5+1) and 72 will be divided in 6 groups to be able to have a statistically significant model, so each group should have 12 teams to conduct experiment.

### 5. Independent variables

The experiment has one independent variable, namely the work place of the team. It is a categorical variable with three categories: home, mix and office. 

### 6. Dependent variables

The dependent variable of the experimental design is the amount of technical debt. Technical debt is measured in time and is thus measured on a continuous scale.

### 7. Specific experiment hypotheses

The design includes one null and one alternative hypothesis:

- h0: The work location has **no** effect on the technical debt. 
- h1: The work location has **an** effect on the technical debt.

### 8. Data collection procedure

SonarQube is a tool used for continuous inspection of code quality and includes several metrics such as technical debt. It is the tool to be used to measure technical debt of the software artifacts produced by the teams.

### 9. Plan for analysis of data to answer hypotheses

As we have only one factor work place, we will do a one-way ANOVA to determine whether there is a significant difference between the the groups.

### 10. Possible threats to validity and replication considerations

*Validity.*
We have focused on the four main types of validity threats discussed by @wohlin2012experimentation:   

1. **Conclusion validity**. The conclusion validity is strongly related to analyzing the outcome and determining if there is a significant effect of the factor. This could be determined by using the different tools provided by R and supporting packages and functions. However, we must analyze the outcome together with the assumptions (such as chosen power, effect size and significance level) to make appropriate conclusions. 
2. **Construct validity**. This aspect is related to the generalization of the results to the theory behind it and is connected to how well the experiment measures what is intended. One threat related to this is the fact that the behavior of the subjects participating in the experiment might be affected just by the fact that they are part of the study. It is a valid threat in our case since it is quite hard to apply the treatment in this study without them being aware of it. 
3. **Internal validity**. If we observe a significant effect of a treatment on the outcome, we might still not be sure that the observed factor was the actual cause. There might exist other factors that we have not included or controlled that effect the outcome. One example could be that employees working from home do not need to commute to work and therefore are less stressed at the beginning of their work day. 
4. ***External validity**. This is described in the replication section below, but summarizing it can be hard to repeat the experiment since there are many specific conditions that can not be measured or controlled in our experiment. 

*Replication.*
Replication is an extremely important aspect since a new knowledge is generally not accepted until it has been repeated and verified by external agents [@juristo2013basics]. According to @juristo2013basics, there are two types of replication: External replication where the experiment is repeated by independent researchers and internal validation which is run within the experiment itself. A possible threat to both internal and external validations is the problem of similarity between repeated experiments. Replication of an experiment aims at repeating the experiment under specific preconditions. In our experiment, there are multiple elements and conditions, such as the team members, the tasks and experience levels which are very specific and thereby hard to replicate.



# Data generation and analysis

### Data generation

*Generating a population of size 72.*

```{r 1}
N <- 72
```

*Supposing the observations come from a normal population and then define a model to generate the data.*

```{r 2}
model <- function(N, X_experience, X_workplace){
 
  ref <- 2 #LE, Office (reference group)

# main effects
 experience_ME <- 0.1
 workplace_Home <- 0.75         
 workplace_Mix <- 0.6         
 
# second order interactions (TODO remove?)
 experienceME_workplaceHome <- 0   # no interactions
 experienceME_workplaceMix <- 0

#input 
 x_experience_ME <- X_experience[1]
 x_workplace_Home <-  X_workplace[1]
 x_workplace_Mix <- X_workplace[2]
 
 response_std <- 1.0  
 
#Linear model that controls the response variable
 techdebt <- ref + experience_ME*x_experience_ME + workplace_Home*x_workplace_Home + workplace_Mix*x_workplace_Mix
 
# Generate normal distribution
 techdebt_out<- rnorm(N, mean=techdebt, sd = response_std) 

 return(techdebt_out)
}
```

*Creating a data frame of population for each group.*

```{r 3}
set.seed(7000)

experience_LE <- c(0)
experience_ME <- c(1)

workplace_Office <- c(0,0)
workplace_Home <- c(1,0)
workplace_Mix <- c(0,1) 

g1 <- data.frame(
Experience = rep('LE', N), 
Workplace = rep('Home', N), 
techdebt=model(
  N=N,
  X_experience = experience_LE,
  X_workplace = workplace_Home
  )
)

g2 <- data.frame(
Experience = rep('ME', N), 
Workplace = rep('Home', N), 
techdebt=model(
  N=N,
  X_experience = experience_ME,
  X_workplace = workplace_Home
  )
)

g3 <- data.frame(
Experience = rep('LE', N), 
Workplace = rep('Mix', N), 
techdebt=model(
  N=N,
  X_experience = experience_LE,
  X_workplace = workplace_Mix
  )
)

g4 <- data.frame(
Experience = rep('ME', N), 
Workplace = rep('Mix', N), 
techdebt=model(
  N=N,
  X_experience = experience_ME,
  X_workplace = workplace_Mix
  )
)

g5 <- data.frame(
Experience = rep('LE', N), 
Workplace = rep('Office', N), 
techdebt=model(
  N=N,
  X_experience = experience_LE,
  X_workplace = workplace_Office
  )
)

g6 <- data.frame(
Experience = rep('ME', N), 
Workplace = rep('Office', N), 
techdebt=model(
  N=N,
  X_experience = experience_ME,
  X_workplace = workplace_Office
  )
)
```

*Creating a balanced sample for each group with the same number of teams in each group.*

```{r 4}
n <- N / 6
all_groups <- list(g1, g2, g3, g4, g5, g6)

#Creating an empty data frame from an existing one (with the same column)
d<-g1[0,]
for(g in all_groups) {
 d<-rbind(d, dplyr::sample_n(g, size=n)) #Appending rows at the end for every group 
}

d$Experience <-as.factor(d$Experience) 
d$Workplace <- as.factor(d$Workplace)

#Set correct levels
levels(d$Experience) <- c("LE", "ME")
levels(d$Workplace) <- c("Office", "Home", "Mix")
```

### Data analysis

*Generating the linear model to fit the data.*

```{r 5}
m1 <- lm(techdebt ~ Workplace + Experience, data=d) 
summary(m1)
```  
Testing normality by using qqPlot and Shapiro-Wilk test.

```{r 5.1}
qqPlot(m1)
shapiro.test(m1$residuals)
```
*Checking whether the model is in good quality by using the function of residualPlot().*

```{r 5.2}
residualPlot(m1)
```


*Presenting the ANOVA table(one-way Anova).*

```{r 5.3}
Anova(m1)
```

*Using Tukey HSD post-hoc test to know the differences among groups.*

```{r 5.4}
TukeyHSD(aov(techdebt ~ Workplace + Experience, data=d))
```

### 1. Sample size from power analysis

TODO

### 2. Half of sample size from power analysis

TODO

# Contributions

All four of us attended the lab. During the lab, we started discussing the design of the experiment. We started by creating a draft registration in *osf.io* which helped guide us through the first steps of the design.

# References